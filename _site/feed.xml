<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-03-12T02:30:48+05:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Usman Asif‚Äôs Tech Journal</title><author><name>Usman Asif</name><email>usman.asif2208@gmail.com</email></author><entry><title type="html">Using Celery with RabbitMQ: Installation &amp;amp; Queue Setup</title><link href="http://localhost:4000/2025/03/12/celery-with-rabbitmq.html" rel="alternate" type="text/html" title="Using Celery with RabbitMQ: Installation &amp;amp; Queue Setup" /><published>2025-03-12T00:00:00+05:00</published><updated>2025-03-12T00:00:00+05:00</updated><id>http://localhost:4000/2025/03/12/celery-with-rabbitmq</id><content type="html" xml:base="http://localhost:4000/2025/03/12/celery-with-rabbitmq.html"><![CDATA[<hr />

<h2 id="-introduction">üöÄ Introduction</h2>

<p>Celery is a powerful distributed task queue system, and RabbitMQ is one of its most commonly used brokers. This guide will walk you through setting up Celery with RabbitMQ, configuring queues, and running tasks efficiently.</p>

<hr />

<h2 id="-installation">üìå Installation</h2>

<h3 id="1Ô∏è‚É£-install-docker">1Ô∏è‚É£ Install Docker</h3>

<p>To run RabbitMQ, you need Docker installed on your system. If you don‚Äôt have it, install it using:</p>

<p><code>
brew install docker  # macOS (use apt or yum for Linux)
</code></p>

<h3 id="2Ô∏è‚É£-start-rabbitmq">2Ô∏è‚É£ Start RabbitMQ</h3>

<p>You can start RabbitMQ using a simple Docker command. First, create an alias for convenience:</p>

<p><code>
alias rmq="docker run -d --name rabbitmq-3 -p 5672:5672 -p 15672:15672 rabbitmq:3-management"
</code></p>

<p>Now start RabbitMQ with:</p>

<p><code>
rmq
</code></p>

<h3 id="3Ô∏è‚É£-verify-the-installation">3Ô∏è‚É£ Verify the Installation</h3>

<p>Check if RabbitMQ is running properly by querying the queues:</p>

<p><code>
curl 'http://guest:guest@localhost:15672/api/queues'
</code></p>

<p>If RabbitMQ is running, it should return <code class="language-plaintext highlighter-rouge">[]</code> (an empty list of queues). If there are errors, run RabbitMQ without <code class="language-plaintext highlighter-rouge">-d</code> to see logs:</p>

<p><code>
docker run --name rabbitmq-3 -p 5672:5672 -p 15672:15672 rabbitmq:3-management
</code></p>

<hr />

<h2 id="-setting-up-celery">üìå Setting Up Celery</h2>

<h3 id="1Ô∏è‚É£-install-celery">1Ô∏è‚É£ Install Celery</h3>

<p>If you haven‚Äôt installed Celery, do so using pip:</p>

<p><code>
pip install celery
</code></p>

<h3 id="2Ô∏è‚É£-configure-celery-with-rabbitmq">2Ô∏è‚É£ Configure Celery with RabbitMQ</h3>

<p>Create a <code class="language-plaintext highlighter-rouge">celery.py</code> file in your Django or Python project:</p>

<p><code>
from celery import Celery</code></p>

<p>app = Celery(‚Äòmy_project‚Äô, broker=‚Äôpyamqp://guest@localhost//‚Äô)</p>

<p>@app.task
def add(x, y):
    return x + y
&lt;/code&gt;</p>

<h3 id="3Ô∏è‚É£-running-celery-worker">3Ô∏è‚É£ Running Celery Worker</h3>

<p>Start a Celery worker with:</p>

<p><code>
celery -A celery worker --loglevel=info
</code></p>

<p>You should see output indicating Celery is connected to RabbitMQ.</p>

<hr />

<h2 id="-creating--managing-queues">üìå Creating &amp; Managing Queues</h2>

<p>RabbitMQ allows you to define and manage queues explicitly. You can do this via the management UI (<code class="language-plaintext highlighter-rouge">http://localhost:15672</code>) or programmatically:</p>

<h3 id="1Ô∏è‚É£-define-a-queue-in-celery">1Ô∏è‚É£ Define a Queue in Celery</h3>

<p>Modify <code class="language-plaintext highlighter-rouge">celery.py</code> to route tasks to specific queues:</p>

<p><code>
app.conf.task_routes = {
    'tasks.add': {'queue': 'math_queue'},
}
</code></p>

<p>Then, start a worker for that queue:</p>

<p><code>
celery -A celery worker -Q math_queue --loglevel=info
</code></p>

<h3 id="2Ô∏è‚É£-creating-a-dead-letter-queue-dlq">2Ô∏è‚É£ Creating a Dead Letter Queue (DLQ)</h3>

<p>To handle failed tasks, configure a DLQ:</p>

<p><code>
app.conf.task_queues = {
    Queue('math_queue', exchange=Exchange('math', type='direct'), routing_key='math'),
    Queue('dlq', exchange=Exchange('dlx', type='direct'), routing_key='dlq'),
}
</code></p>

<p>This ensures failed tasks are sent to <code class="language-plaintext highlighter-rouge">dlq</code> for later processing.</p>

<hr />

<h2 id="-executing-tasks">üìå Executing Tasks</h2>

<p>To test your Celery setup, open a Python shell:</p>

<p><code>
from celery import Celery
app = Celery('my_project', broker='pyamqp://guest@localhost//')</code></p>

<p>result = app.send_task(‚Äòtasks.add‚Äô, args=[10, 5], queue=‚Äômath_queue‚Äô)
print(result.get())
&lt;/code&gt;</p>

<p>This should output <code class="language-plaintext highlighter-rouge">15</code> after processing the task.</p>

<hr />

<h2 id="-conclusion">üéØ Conclusion</h2>

<p>You‚Äôve now set up Celery with RabbitMQ, created custom queues, and executed tasks asynchronously. This setup ensures scalable and reliable background task execution.</p>

<p>Happy coding! üöÄ</p>]]></content><author><name>Usman Asif</name></author><summary type="html"><![CDATA[A step-by-step guide on setting up Celery with RabbitMQ, including installation, queue creation, and task execution.]]></summary></entry><entry><title type="html">Understanding Celery: Distributed Task Queues in Django</title><link href="http://localhost:4000/2025/03/11/celery-overview.html" rel="alternate" type="text/html" title="Understanding Celery: Distributed Task Queues in Django" /><published>2025-03-11T00:00:00+05:00</published><updated>2025-03-11T00:00:00+05:00</updated><id>http://localhost:4000/2025/03/11/celery-overview</id><content type="html" xml:base="http://localhost:4000/2025/03/11/celery-overview.html"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>In modern web applications, certain tasks‚Äîlike sending emails, processing images, or handling background jobs‚Äîcan be time-consuming and shouldn‚Äôt block user requests. This is where <strong>Celery</strong> comes in. Celery is a powerful <strong>distributed task queue</strong> that enables you to process tasks asynchronously using <strong>queues and workers</strong>.</p>

<p>In this post, we‚Äôll dive into:</p>
<ul>
  <li>What Celery is and why it‚Äôs useful</li>
  <li>How Celery uses <strong>queues</strong> to manage tasks</li>
  <li>The role of <strong>workers</strong> in processing those tasks</li>
  <li>How to set up Celery in a Django project</li>
</ul>

<hr />

<h2 id="what-is-celery">What is Celery?</h2>

<p>Celery is an <strong>asynchronous task queue</strong> that allows you to run background jobs in a distributed environment. Instead of running a heavy computation task inside a Django view (blocking the request), you send the task to a queue, and a Celery <strong>worker</strong> picks it up and executes it in the background.</p>

<h3 id="why-use-celery">Why Use Celery?</h3>
<ul>
  <li><strong>Improves performance</strong> ‚Äì Background tasks don‚Äôt block the main application.</li>
  <li><strong>Handles long-running jobs</strong> ‚Äì Ideal for tasks like sending emails, generating reports, or processing large datasets.</li>
  <li><strong>Supports distributed execution</strong> ‚Äì You can scale by adding more workers to process tasks in parallel.</li>
  <li><strong>Built-in retries</strong> ‚Äì If a task fails, Celery can automatically retry it based on your configuration.</li>
</ul>

<hr />

<h2 id="how-celery-uses-queues">How Celery Uses Queues</h2>

<p>A <strong>queue</strong> is a buffer where tasks wait to be executed. Celery sends tasks to message brokers like <strong>RabbitMQ</strong> or <strong>Redis</strong>, which act as intermediaries between the Django app and Celery workers.</p>

<p>Here‚Äôs a typical Celery workflow:</p>
<ol>
  <li><strong>Django App</strong> sends a task to Celery.</li>
  <li>The task is placed in a <strong>queue</strong> (stored in Redis or RabbitMQ).</li>
  <li>A <strong>worker</strong> picks up the task from the queue and processes it.</li>
  <li>Once completed, the worker sends back the result (if required).</li>
</ol>

<h3 id="task-queues-in-celery">Task Queues in Celery</h3>
<p>Celery supports multiple queues to help prioritize different types of tasks. Some common queue setups:</p>
<ul>
  <li><strong>Default queue</strong> ‚Äì Where all tasks go if no queue is specified.</li>
  <li><strong>High-priority queue</strong> ‚Äì For urgent tasks that need immediate processing.</li>
  <li><strong>Low-priority queue</strong> ‚Äì For background tasks that can wait.</li>
  <li><strong>Dead Letter Queue (DLQ)</strong> ‚Äì For failed tasks that need manual inspection.</li>
</ul>

<p>In Django, you can configure Celery to route tasks to specific queues based on task type.</p>

<hr />

<h2 id="celery-workers-processing-tasks">Celery Workers: Processing Tasks</h2>

<p>A <strong>worker</strong> is a process that listens for incoming tasks from a queue and executes them. You can run multiple workers on different servers to <strong>scale processing power</strong>.</p>

<p>To start a worker, use:<br />
<code>
celery -A myproject worker --loglevel=info
</code></p>]]></content><author><name>Usman Asif</name></author><summary type="html"><![CDATA[A deep dive into how Celery handles distributed task queues in Django, including best practices and optimizations.]]></summary></entry></feed>