<hr />

<h2 id="-introduction">🚀 Introduction</h2>

<p>Celery is a powerful distributed task queue system, and RabbitMQ is one of its most commonly used brokers. This guide will walk you through setting up Celery with RabbitMQ, configuring queues, and running tasks efficiently.</p>

<hr />

<h2 id="-installation">📌 Installation</h2>

<h3 id="1️⃣-install-docker">1️⃣ Install Docker</h3>

<p>To run RabbitMQ, you need Docker installed on your system. If you don’t have it, install it using:</p>

<p><code>
brew install docker  # macOS (use apt or yum for Linux)
</code></p>

<h3 id="2️⃣-start-rabbitmq">2️⃣ Start RabbitMQ</h3>

<p>You can start RabbitMQ using a simple Docker command. First, create an alias for convenience:</p>

<p><code>
alias rmq="docker run -d --name rabbitmq-3 -p 5672:5672 -p 15672:15672 rabbitmq:3-management"
</code></p>

<p>Now start RabbitMQ with:</p>

<p><code>
rmq
</code></p>

<h3 id="3️⃣-verify-the-installation">3️⃣ Verify the Installation</h3>

<p>Check if RabbitMQ is running properly by querying the queues:</p>

<p><code>
curl 'http://guest:guest@localhost:15672/api/queues'
</code></p>

<p>If RabbitMQ is running, it should return <code class="language-plaintext highlighter-rouge">[]</code> (an empty list of queues). If there are errors, run RabbitMQ without <code class="language-plaintext highlighter-rouge">-d</code> to see logs:</p>

<p><code>
docker run --name rabbitmq-3 -p 5672:5672 -p 15672:15672 rabbitmq:3-management
</code></p>

<hr />

<h2 id="-setting-up-celery">📌 Setting Up Celery</h2>

<h3 id="1️⃣-install-celery">1️⃣ Install Celery</h3>

<p>If you haven’t installed Celery, do so using pip:</p>

<p><code>
pip install celery
</code></p>

<h3 id="2️⃣-configure-celery-with-rabbitmq">2️⃣ Configure Celery with RabbitMQ</h3>

<p>Create a <code class="language-plaintext highlighter-rouge">celery.py</code> file in your Django or Python project:</p>

<p><code>
from celery import Celery</code></p>

<p>app = Celery(‘my_project’, broker=’pyamqp://guest@localhost//’)</p>

<p>@app.task
def add(x, y):
    return x + y
&lt;/code&gt;</p>

<h3 id="3️⃣-running-celery-worker">3️⃣ Running Celery Worker</h3>

<p>Start a Celery worker with:</p>

<p><code>
celery -A celery worker --loglevel=info
</code></p>

<p>You should see output indicating Celery is connected to RabbitMQ.</p>

<hr />

<h2 id="-creating--managing-queues">📌 Creating &amp; Managing Queues</h2>

<p>RabbitMQ allows you to define and manage queues explicitly. You can do this via the management UI (<code class="language-plaintext highlighter-rouge">http://localhost:15672</code>) or programmatically:</p>

<h3 id="1️⃣-define-a-queue-in-celery">1️⃣ Define a Queue in Celery</h3>

<p>Modify <code class="language-plaintext highlighter-rouge">celery.py</code> to route tasks to specific queues:</p>

<p><code>
app.conf.task_routes = {
    'tasks.add': {'queue': 'math_queue'},
}
</code></p>

<p>Then, start a worker for that queue:</p>

<p><code>
celery -A celery worker -Q math_queue --loglevel=info
</code></p>

<h3 id="2️⃣-creating-a-dead-letter-queue-dlq">2️⃣ Creating a Dead Letter Queue (DLQ)</h3>

<p>To handle failed tasks, configure a DLQ:</p>

<p><code>
app.conf.task_queues = {
    Queue('math_queue', exchange=Exchange('math', type='direct'), routing_key='math'),
    Queue('dlq', exchange=Exchange('dlx', type='direct'), routing_key='dlq'),
}
</code></p>

<p>This ensures failed tasks are sent to <code class="language-plaintext highlighter-rouge">dlq</code> for later processing.</p>

<hr />

<h2 id="-executing-tasks">📌 Executing Tasks</h2>

<p>To test your Celery setup, open a Python shell:</p>

<p><code>
from celery import Celery
app = Celery('my_project', broker='pyamqp://guest@localhost//')</code></p>

<p>result = app.send_task(‘tasks.add’, args=[10, 5], queue=’math_queue’)
print(result.get())
&lt;/code&gt;</p>

<p>This should output <code class="language-plaintext highlighter-rouge">15</code> after processing the task.</p>

<hr />

<h2 id="-conclusion">🎯 Conclusion</h2>

<p>You’ve now set up Celery with RabbitMQ, created custom queues, and executed tasks asynchronously. This setup ensures scalable and reliable background task execution.</p>

<p>Happy coding! 🚀</p>
